{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f16ef06c",
   "metadata": {},
   "source": [
    "<img src=\"https://2wz2rk1b7g6s3mm3mk3dj0lh-wpengine.netdna-ssl.com/wp-content/uploads/2018/08/kinetica_logo.svg\" alt=\"Kinetica Logo\" width=\"300\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c1d8ef",
   "metadata": {},
   "source": [
    "### The Database for Space and Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0872b9d",
   "metadata": {},
   "source": [
    "![What we want, visualized in side-by-side images](images/header_image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2433ac05",
   "metadata": {},
   "source": [
    "# Spatial Analytics: Optimizing Graphs on Geospatial Features\n",
    "## _For Things That Matter:_ Enjoyable Scenic Drives\n",
    "\n",
    "\n",
    "_By Saif Ahmed, Scott Little, Julian Jenkins, Kaan Karamete, Pat Khunachak, and Chad Meley_\n",
    "\n",
    "\n",
    "We are all accustomed to satellite navigation and some of the options it gives us -- avoiding tolls, avoiding highways, etc. But what if we used geospatial features from the world around us to hyper-optimize to what we want? Perhaps we want the most scenic route home, or the most well-lit. Perhaps this this weekend's ride in the convertable calls for the quietest road.\n",
    "\n",
    "We can do all this using a road networks as graphs, geo-spatial features as graph networks and graph optimizations. And we'll do it together below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa98476",
   "metadata": {},
   "source": [
    "![Side by Side Comparison](images/side_by_side_comparison.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6365b143",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "- [Problem Setup](#problem-setup)\n",
    "- [Caveats & Simplifying Assumptions](#caveats-simplifying-assumptions)\n",
    "-  [Getting Started](#getting-started)\n",
    "   * [Required Data](#required-data)\n",
    "   * [Data Wrangling](#data-wrangling)\n",
    "-  [Implementation](#implementation)\n",
    "-  [Results](#results)\n",
    "-  [Taking This Further](#taking-this-further)\n",
    "-  [Further Reading](#further-reading)\n",
    "-  [Documentation](#documentation)\n",
    "-  [About Us](#about-us)\n",
    "-  [Contact Us](#contact-us)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552ce267",
   "metadata": {},
   "source": [
    "## Problem Setup\n",
    "\n",
    "We set this problem up as a graph optimization with edge weights that favor the traversal of streets with our attribute of choice. In this exercise we choose road beauty, since scenic drives are something most are familiar with. Later in the notebook, we explore the \"Eye of the Beholder\" concept -- that beauty itself is of course subjective; and we propose an easy way for individuals to calculate beauty scores important to themselves personally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b62d4c2",
   "metadata": {},
   "source": [
    "### Caveats & Simplifying Assumptions\n",
    "\n",
    "* We sample road images about 100ft apart, but the user is free to sample at any frequency they want, assuming they have inference compute capacity. For rural routes, 100ft is probably too dense. For urban routes, 100ft could be too little (rely on Mapillary for these, that will provide more density.)\n",
    "* We took photos with a variety of cameras -- iPhones, GoPros, crowdsourced from Mapillary. This can affect scores since wide-angle cameras will capture more sky (and thus overweight sky scores). We demonstrate the concept, but the user is free to homogenize source images for even more consistent scoring.\n",
    "* We ignore direction of travel vs image heading, though this could have a slight impact, especially in urban environments and on mountainous roads (where one side is mostly sky and the other is mostly mountain)\n",
    "* We personally sampled a variety of environments -- urban (Brooklyn NY; Arlington VA; Washington DC), suburban (Ithaca NY; UC Berkeley; Princeton NJ), and rural (Shanendoah Mountain Regions in VA). We also pulled multiple metro areas from Mapillary for greater scale.\n",
    "* Larger inference workloads were done on 4x NVIDIA v100 -- but CPUs will also suffice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1470e3a",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "To get started immediately, you can run everything below quickly on the [Developer Edition](https://www.kinetica.com/try/) or via [Kinetica Cloud](https://www.kinetica.com/kinetica-as-a-service-on-azure/)\n",
    "\n",
    "Then, import this repo from GitHub:\n",
    "\n",
    "```\n",
    "\tgit clone git@github.com:kineticadb/pretty-trip.git\n",
    "\tcd saferun\n",
    "```\n",
    "\n",
    "Set up python dependencies:\n",
    "\n",
    "```\n",
    "\tpip install -r requirements.txt\n",
    "```\n",
    "Export your credentials as environment variables and the the [Jupyter notebook](https://github.com/kineticadb/saferoute/blob/master/start-here.ipynb) will lead you from start to finish!\n",
    "\n",
    "```\t\n",
    "\texport KINETICA_HOST='https://xyz.eastus.cloudapp.azure.com/abc/gpudb-0'\n",
    "\texport KINETICA_USER='kadmin'\n",
    "\texport KINETICA_PASS='xyz'\n",
    "\tjupyter notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f05635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import gpudb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c855aa9e",
   "metadata": {},
   "source": [
    "We'll be interacting with Kinetica along the way to load data, set up graph optimziations, and view results. Make sure to export these environment variables (or override them below): **KINETICA_HOST, KINETICA_USER, KINETICA_PASS**. All the code below is Python, but many are SQL commands excuted via Python directly against the database you connect to below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7808647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "KINETICA_HOST = os.getenv('KINETICA_HOST', \"http://localhost:9191\")\n",
    "KINETICA_USER = os.getenv('KINETICA_USER', \"kadmin\")\n",
    "KINETICA_PASS = os.getenv('KINETICA_PASS')\n",
    "db = gpudb.GPUdb(host=KINETICA_HOST, username=KINETICA_USER, password=KINETICA_PASS)\n",
    "exec_result = db.execute_sql_and_decode('show system properties')['status_info']['status']\n",
    "print(exec_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ca9a6d",
   "metadata": {},
   "source": [
    "We dont have to do this, but having all our assets under a single schema is useful to organize our work. It also allows us to quickly clear out project assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f4d33cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'schema_name': 'pretty_trip',\n",
       " 'info': {},\n",
       " 'status_info': {'status': 'OK',\n",
       "  'message': '',\n",
       "  'data_type': 'create_schema_response',\n",
       "  'response_time': 0.0137}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.create_schema(\"pretty_trip\", options={'no_error_if_exists': \"true\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cb2332",
   "metadata": {},
   "source": [
    "### Required Data\n",
    "\n",
    "We will be using the Open Street Maps (OSM) dataset to drive our optimizations:\n",
    "* DC Road Network Dataset: https://download.geofabrik.de/north-america/us/district-of-columbia.html\n",
    "* More about OSM: https://www.openstreetmap.org/\n",
    "* Photos taken for specific exercises\n",
    "    * DC --> Fairfax Virginia, Multiple Routes: * https://kinetica-community.s3.amazonaws.com/pretty-trip/northern_virginia.zip\n",
    "    * Identifying Hilly Areas: https://kinetica-community.s3.amazonaws.com/pretty-trip/shanendoah_virginia.zip\n",
    "    * Identifying Winding Roads: https://kinetica-community.s3.amazonaws.com/pretty-trip/bedford_pennsylvania.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b6c6f0",
   "metadata": {},
   "source": [
    "Lets start with creating the target tables and loading our CSVs into them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb36409",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_result = db.execute_sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE \"pretty_trip\".\"dc_osm\"\n",
    "(\n",
    "   \"WKT\" GEOMETRY NOT NULL,\n",
    "   \"osm_id\" BIGINT NOT NULL,\n",
    "   \"code\" INTEGER NOT NULL,\n",
    "   \"fclass\" VARCHAR (64, dict) NOT NULL,\n",
    "   \"name\" VARCHAR (256),\n",
    "   \"ref\" VARCHAR (128, dict),\n",
    "   \"oneway\" VARCHAR (32) NOT NULL,\n",
    "   \"maxspeed\" INTEGER NOT NULL,\n",
    "   \"layer\" INTEGER NOT NULL,\n",
    "   \"bridge\" VARCHAR (32) NOT NULL,\n",
    "   \"tunnel\" VARCHAR (32) NOT NULL\n",
    ")\n",
    "\"\"\")\n",
    "exec_result['status_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f58665",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_result = db.execute_sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE \"pretty_trip\".\"location_beauty\"\n",
    "(\n",
    "   \"longitude\" DOUBLE NOT NULL,\n",
    "   \"latitude\" DOUBLE NOT NULL,\n",
    "   \"beauty\" DOUBLE NOT NULL\n",
    ")\n",
    "\"\"\")\n",
    "exec_result['status_info']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e971fbfe",
   "metadata": {},
   "source": [
    "Open Street Maps data needs to be converted to tabular form to load as a graph. You can do this wrangling yourself, but we've also done it for you...in case you wish to skip that step. We hosted the wrangled street maps data on S3. Below we regiser our S3 bucket as a data source on Kinetica and then load the CSVs into the table we just created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea49cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_result = db.execute_sql(\"\"\"\n",
    "CREATE OR REPLACE DATA SOURCE \"pt-road-network-osm\"\n",
    "LOCATION = 'S3' \n",
    "WITH OPTIONS (\n",
    "    ANONYMOUS = 'true',\n",
    "    BUCKET NAME = 'kinetica-community',\n",
    "    REGION = 'us-east-1'\n",
    ")\n",
    "\"\"\")\n",
    "exec_result['status_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362fbce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_result = db.execute_sql(\"\"\"\n",
    "LOAD DATA INTO \"pretty_trip\".\"dc_osm\"\n",
    "FROM FILE PATHS 'pretty-trip/dc_nova__road_network.csv'\n",
    "FORMAT TEXT\n",
    "WITH OPTIONS (\n",
    "    DATA SOURCE = 'pt-road-network-osm'\n",
    ")\n",
    "\"\"\")\n",
    "exec_result['status_info']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83a93d5",
   "metadata": {},
   "source": [
    "The data just loaded is shown below. The key feature, of course, is the series of coordinate pairs forming the graph network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33d7d53",
   "metadata": {},
   "source": [
    "![Side by Side Comparison](images/osm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d692567b",
   "metadata": {},
   "source": [
    "However, the data is best visualized as a WMS:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f20248d",
   "metadata": {},
   "source": [
    "![Side by Side Comparison](images/wms.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe2891f",
   "metadata": {},
   "source": [
    "## Implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf4b8d9",
   "metadata": {},
   "source": [
    "### Prep Streetlight Data\n",
    "\n",
    "First we must convert the street light points into polygons inorder to create buffers around the lights, which represents their lightspan. For this project we have estimated 9 meters as our buffer radius, which is the average height of all of the streetlights in this data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4816515",
   "metadata": {},
   "source": [
    "### Graph\n",
    "\n",
    "First we will create the graph with weights. Our weights are distance based (not time based)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a302e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_result = db.create_graph(\n",
    "    graph_name = \"dc_osm_graph\", \n",
    "    directed_graph = False,\n",
    "    edges = [\n",
    "    \"pretty_trip.osm_small.osm_id AS EDGE_ID\",\n",
    "    \"pretty_trip.osm_small.WKT AS EDGE_WKTLINE\"\n",
    "  ],\n",
    "    weights = [\n",
    "    \"pretty_trip.osm_small.osm_id AS WEIGHTS_EDGE_ID\",\n",
    "    \"ST_Length(pretty_trip.osm_small.WKT,1)/(ST_NPoints(pretty_trip.osm_small.WKT)-1) + ((1- pretty_trip.osm_small.light)*20) AS WEIGHTS_VALUESPECIFIED\"\n",
    "  ],\n",
    "    options = {\n",
    "   \n",
    "    \"merge_tolerance\": \"0.00001\",\n",
    "    \"use_rtree\": \"false\",\n",
    "    \"min_x\": \"-180\",\n",
    "    \"max_x\": \"180\",\n",
    "    \"min_y\": \"-90\",\n",
    "    \"max_y\": \"90\",\n",
    "    \"recreate\": \"true\",\n",
    "    \"modify\": \"false\",\n",
    "    \"export_create_results\": \"false\",\n",
    "    \"enable_graph_draw\": \"true\",\n",
    "    \"save_persist\": \"false\",\n",
    "    \"sync_db\": \"false\",\n",
    "    \"add_table_monitor\": \"false\",\n",
    "    \"graph_table\": \"ki_home.dc_osm_graph_table\",\n",
    "    \"add_turns\": \"false\",\n",
    "    \"turn_angle\": \"60.0\",\n",
    "    \"is_partitioned\": \"false\"\n",
    "  \n",
    "}\n",
    ")\n",
    "exec_result['status_info']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f7f99e",
   "metadata": {},
   "source": [
    "For location images, you have several options for images:\n",
    "* Take your own photos and ingest them\n",
    "* Use the Mapillary ingestor (DockerHub: kinetica/ctnr-kml-byoc-sample-mapillary) and batch ingest for areas of choice\n",
    "* Use our dataset (if you want to quickly run thru this exercise)\n",
    "\n",
    "And finally, for beauty scoring, you have several choices:\n",
    "* Load your own scores (from any source of choice!)\n",
    "* Use the ready-deployable AAW container for scoring:\n",
    "    * DockerHub: CPU: kinetica/ctnr-kml-bbox-ml-deep-img-segment-cpu\n",
    "    * DockerHub: GPU: kinetica/ctnr-kml-bbox-ml-deep-img-segment-gpu\n",
    "* Use our dataset of already-inferenced images (if you want to quickly run thru this exercise, see all_inferences_scored.json)\n",
    "\n",
    "Below, we use container results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6723bf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "with open(\"all_inferences_scored.json\", \"r\") as read_file:\n",
    "    all_pts = json.load(read_file)\n",
    "pts = [OrderedDict([('latitude', k['location'][\"gps_latitude_decimal\"]), \n",
    "                    ('longitude', k['location'][\"gps_longitude_decimal\"]),\n",
    "                    ('beauty', k[\"score\"])]) for k in all_pts]\n",
    "db.insert_records(table_name=\"pretty_trip.location_beauty\", data=pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5e86fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_result = db.solve_graph(\n",
    "    graph_name = \"dc_osm_graph\",\n",
    "    solver_type = \"SHORTEST_PATH\",\n",
    "    source_nodes = [\n",
    "    \"{'POINT(-77.037124 38.926142)'} AS NODE_WKTPOINT\"\n",
    "  ],\n",
    "    destination_nodes = [\n",
    "    \"{'POINT(-77.042686 38.922676)'} AS NODE_WKTPOINT\"\n",
    "  ],\n",
    "    solution_table = \"pretty_trip.scenic_path_solved\",\n",
    "    {\n",
    "    \"export_solve_results\": \"false\",\n",
    "    \"min_solution_radius\": \"0.0\",\n",
    "    \"max_solution_radius\": \"0.0\",\n",
    "    \"max_solution_targets\": \"0\",\n",
    "    \"accurate_snaps\": \"true\",\n",
    "    \"left_turn_penalty\": \"0.0\",\n",
    "    \"right_turn_penalty\": \"0.0\",\n",
    "    \"intersection_penalty\": \"0.0\",\n",
    "    \"sharp_turn_penalty\": \"0.0\",\n",
    "    \"output_edge_path\": \"false\",\n",
    "    \"output_wkt_path\": \"true\"\n",
    "  \n",
    "}\n",
    ")\n",
    "exec_result['status_info']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee99e39",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Below is a routing example from Southern Washington DC to Kinetica's HQ in Northern Virginia. We also have a sample of images and scores along the path which contributed to the different routing results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a84b9e",
   "metadata": {},
   "source": [
    "Here is a before and after of the generated path based on the wieghts.![shortest.png](images/results.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5142c866",
   "metadata": {},
   "source": [
    "![lit.png](images/components.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464f567a",
   "metadata": {},
   "source": [
    "### Taking it Further\n",
    "\n",
    "Do you like winding roads? We can easily identify winding roads on images by road/lane tracking using CV techniques. You can try it on this dataset from Skyline Drive in Shanendoah Virginia: https://kinetica-community.s3.amazonaws.com/pretty-trip/shanendoah_virginia.zip\n",
    "\n",
    "But are inferencing images the best way to find winding roads? Image inference and CV is costly, and a better way may be to calculate angles on subsequent road segments. You can do this directly with the Open Street Maps dataset we used above.\n",
    "\n",
    "A similar, but easier exercise would be identifying drives with rolling hills and steady up-and-down country roads. This is because elevation data is easily join-able. You can obtain elevation data from the US Geological Survey (USGS: https://www.usgs.gov/core-science-systems/national-geospatial-program/national-map). Whatever you do not have, you can interpolate and generate isochrones (see: https://docs.kinetica.com/7.1/guides/isochrones/) See if you can eyeball the results against this beautiful drive in Bedford Pennsylvania: https://kinetica-community.s3.amazonaws.com/pretty-trip/bedford_pennsylvania.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458b6f31",
   "metadata": {},
   "source": [
    "### Other Applications\n",
    "* Autonomous Vehicles: Roads with fewer pedestrians\n",
    "* Government: Crowd-source route data on potholes\n",
    "* Government: Real-time crowd-source routes with blockages (fallen trees, debris, fallen branches)\n",
    "* Government: Municipality and State contributed data to optimize mapping routes for tourists\n",
    "* P&C Insurance: Smart-route commercial traffic to minimize risk (Opt in)\n",
    "* P&C Insurance: Score individual traffic for risk aversion based on routes, issue policy discounts (Opt in)\n",
    "* Rental Car Companies: Score individual rentals for safety scored discounts\n",
    "* Waze / Google Maps: Offer a more scenic route w/ similar ETA; offer construction avoidance\n",
    "* Zillow / Trulia / Redfin: Beyond zestimates, commute beauty scoring\n",
    "* Cyclers: Avoid steep grades; avoid roads with twigs/branches on path\n",
    "* Pedestrians: Avoid major road crossings; quiet routes; beautiful roads\n",
    "* Hikers: Chained trails with minimum/maximum difficulty grade\n",
    "* Hikers: Optimal loop size from trailhead\n",
    "* Bikers: Safe and scenic bike loops that avoids large roadways "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bd2b8f",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "- [Full Documentation](https://docs.kinetica.com/7.1/)\n",
    "- [Topic Based Quickstart Guides](https://docs.kinetica.com/7.1/guides/)\n",
    "\n",
    "## About Us\n",
    "Kinetica is an analytics database for fusing data across streams and data lakes to unlock value from spatial and temporal data at scale and speed. Learn about us [here](https://www.kinetica.com/).\n",
    "\n",
    "## Contact Us\n",
    "- Follow on Github: <a class=\"github-button\" href=\"https://github.com/kineticadb\" data-size=\"large\" aria-label=\"Follow @kineticadb on GitHub\">Follow @kineticadb</a>\n",
    "- Email: [support@kinetica.com](mailto:support@kinetica.com)\n",
    "- Slack: [Slack](https://www.kinetica.com/slack)\n",
    "- Visit: [https://www.kinetica.com/contact/](https://www.kinetica.com/contact/)\n",
    "\n",
    "## License\n",
    "\n",
    "The software is licensed under the MIT license."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
